## 第一章 并行计算与并行计算机结构模型

#### 1.2 单处理机与指令级并行

* 加快CPU执行速度：
  * 流水线与超标量
  * 超长指令字
  * 向量指令
* 减少存储延迟
  * 存储器性能的局限
  * 使用高速缓存
* 改善输入输出以及网络性能

#### 1.3 多核处理器与线程级并行

* 片上多处理器(CMP)，即多核处理器、单芯片多处理器
* 实例

#### 1.4 并行计算机体系结构

* 区分多个CPU和多核CPU：https://www.jianshu.com/p/7969ea0d5526

* 并行计算机结构模型

  分类

  * 单指令多数据流(SIMD)计算机
  * 并行向量处理机(PVP)
  * 对称多处理机(SMP)
  * 大规模并行处理机(MPP)
  * 工作站机群(COW)
  * 分布共享存储多处理机(DSM)

  后五种统称为多指令多数据流计算机(MIMD),图参考ppt PC1 p6

* 当代并行机的公用结构:书p16

* 并行计算机访存模型

  * UMA：均匀存储访问
    * 所有处理器访问任何存储单元的时间都相同
    * SIMD一般是UMA模型
    * 根据I/O设备访问情况分为SMP和非对称多处理机 ，书p17
  * NUMA：非均匀存储访问
    * 处理器访问不同存储器的时间不一样
  * COMA(Cache-Only)：全高速缓存存储访问
    * 是NUMA的一种特例
  * CC-NUMA：高速缓存一致性非均匀存储访问
    * 是一个DSM多处理机系统
  * NORMA（非远程存储访问）
    * 所有存储器都是私有的，仅支持其对应的处理器的访问
    * 系统多个计算结点通过消息传递互联网络连接而成

* 总结图：p20

* cache 一致性问题

  * 高速缓存写策略：写直达、写回 （书p22
  * cache一致性问题解决思路
    * 基于侦听：即所有处理器监听总线，当共享数据被改变时，则清除自己错误的缓存
    * 谁改写的就直接广播该值

## 第二章 并行计算机系统互连与基本通信操作

#### 2.1 并行计算机互连网络

##### 系统互连

* ppt4,5两个图示
* 网络性能指标
  * 节点度（Node Degree）：射入或射出一个节点的边数。在单向网络中，入射和出射边之和称为节点度。 
  * 网络直径（Network Diameter）： 网络中任何两个节点之间的最长距离，即最大路径数。 
  * 对剖宽度（Bisection Width） ：对分网络各半所必须移去的最少边数 
  * 对剖带宽（ Bisection Bandwidth）:每秒钟内，在最小的对剖平面上通过所有连线的最大信息位（或字节）数 
  * 如果从任一节点观看网络都一样，则称网络为对称的

##### 静态互连网络

* 处理单元间有着固定连接的一类网络， 在程序执行期间，这种点到点的链接保持不变；
* 典型的静态网络有一维线性阵列、二维网孔、树连接、超立方网络、立方环、洗牌交换网、蝶形网络等
* 一维线性阵列
  * 并行机中最简单、最基本的互连方式，
  * 每个节点只与其左、右近邻相连，也叫二近邻连接， 
  * N个节点用N-1条边串接之，内节点度为2，直径为 N-1，对剖宽度为1 
  * 当首、尾节点相连时可构成循环移位器，在拓扑结构上等同于环，环可以是单向的或双向的，其节点度恒为2，直径或为N/2(下取整) （双向环）或为N-1（单向环），对剖宽度为2 
* 二维网孔：ppt10
  * 正常网孔
  * Illiac网孔
  * 2-D环绕
* 二叉树、星型网络
* 超立方：n-立方、n-立方环
* 嵌入：
  * 将网络中的各节点映射到另一个网络中去 
  * 用膨胀（Dilation）系数来描述嵌入的质量，它是指被嵌入网络中的一条链路在所要嵌入的网络中对应所需的最大链路数 
  * 如果该系数为1，则称为完美嵌入。 
  * 环网可完美嵌入到2-D环绕网中 
  * 超立方网可完美嵌入到2－D环绕网中
* 总的比较：ppt16

##### 动态互连网络

* 用交换开关构成的，可按应用程序的要求动态地改变连接组态；典型的动态网络包括总线、交叉开关和多级互连网络等。
* 总线：多处理机总线系统的主要问题包括总线仲裁、中断处理、协议转换、 快速同步、高速缓存一致性协议、分事务、总线桥和层次总线扩展等
* 交叉开关
  * 单级交换网络，可为每个端口提供更高的带宽。象电话交换机 一样，交叉点开关可由程序控制动态设置其处于“开”或“关” 状态，而能提供所有（源、目的）对之间的动态连接。 
  * 交叉开关一般有两种使用方式：一种是用于对称的多处理机或多计算机机群中的处理器间的通信；另一种是用于SMP服务器或向量超级计算机中处理器和存储器之间的存取。
* 多级互连网络(MIN)：由单级交叉开关级联起来
* 图见书p44-45
* 交换开关模块：ppt20
* 级间互连 ：ppt20
* 各类比较：ppt21

##### 标准互连网络

#### 2.2 选路方法与开关技术

##### 预备知识

* 选路
* 消息、信包、片及其相互关系
* 互联网络、传输节点结构
  * 描述：拓扑、选路算法、流控制
  * 重要指标：传输时延、吞吐量
  * 节点（开关）结构
* 一些术语：
  * 信道带宽b：每个信道有w位宽和信号传输率f = 1/t (t是时 钟周期), b = wf bits/sec 
  * 节点和开关的度：与节点和开关相连的信道数目 
  * 路径：信包在网络中走过的开关和链路(link)序列 
  * 路由长度或距离：路由路径中包括的链路(link)数目 
* **信包传输性能参数** 
  * 启动时间$t_s$ (startup time)：准备信包头信息等 
  * 节点延迟时间$t_h$ (per-hop time)：信包头穿越相邻节点的时间 ，即整个信息在一条线路上的传输时间
  * 字传输时间$t_w$ (transfer time)：传输每个字的时间 ，类似于从节点发送到线路上的时间
  * 链路数l 、信包大小m
* 选路算法三种机制
  * 基于算术
  * 基于源地址
  * 基于查表
* 选路方式：ppt36

##### 选路方法

* 分类 
  * 最短路径/非最短路径(贪心选路/随机选路)， 如维序选路是贪心的，二阶段维序选路是随机的 
  * 确定选路/自适应选路(寻径确定/寻径视网络状况) 
* 维序选路(Dimension-Ordered Routing)： 一种确定的最短路径选路 
  * 二维网孔中的维序选路: X-Y选路 ，ppt39-40
    * 存在链路竞争问题
  * 超立方中的维序选路: E-立方选路，ppt41-42

##### 开关技术

* 图见ppt47-48

* 存储转发（SF）选路![image-20210517214323286](D:\科大\大三下\并行计算\image\image-20210517214323286.png)
* 切通（CT）选路![image-20210517214846126](D:\科大\大三下\并行计算\image\image-20210517214846126.png)
* 虫孔选路（Warmhole）

#### 2.3 单一信包一到一传输

* ppt50， 一般会忽略$t_h$

#### 2.4 一到多播送

* **含义见书p63总结**

##### 使用SF（主要分析时间）

* 环
* 环绕网孔
* 超立方

##### 使用CT

* 环
* 网孔
* 超立方

#### 2.5 多到多播送

##### 使用SF

* 环
* 环绕网孔
* 超立方

##### 使用CT

* 时间完全同SF

## 第五章 并行算法与并行计算模型

* PC5 ppt
* 总结：
  * 战略层：三种设计策略：串改并；全新设计；借用法（CH6），PCAM ch8
  * 战术层：5种基本设计技术 ch7
  * 领域层：数值计算(矩阵乘、FFT、稀疏乘、线性法求解等)

#### 5.1 并行算法的基础知识

* 并行算法的定义和分类

* 并行算法的表达：par-do语句；for all语句

  * 并行算法的表达形式：4种 (PC5 ppt p6-7)
    * SPMD：单程序多数据流  /  MPMD：多程序多数据流
    * 并行循环
    * 并行块 ：fork/join模式
    * 同步/通信

* 并行算法的复杂性度量

  * 串行算法复杂性度量：最坏情况复杂度、期望复杂度

  * 并行算法复杂性度量指标

    * 运行时间t(n)：计算时间+通讯时间

    * 处理器数p(n)

    * 并行算法成本c(n)=t(n)*p(n)

    * 成本最优性：WT最优（ppt8）

    * 总运算量W(n)：总操作步数

      Brent定理

  * 阻塞通讯与非阻塞通讯

* 求n个数和的并行算法：ppt13-14

  ==低层描述的代码没太看懂？？==

* 并行算法里的同步与通信

  * 同步概念、同步语句示例

    * 临界区：轻量级
    * 锁：重量级，开销更大
    * wait/join操作，避免主线程非阻塞运行结束

  * 并行算法里的通信

    * 用通信原语表达

      * 共享存储多处理机：global read, global write
      * 分布存储的多计算机：send(X,i) , receive(Y,j)

    * 示例：分布存储多计算机上的矩阵向量乘算法

      ==变式：ppt20，思考？==

#### 5.2 并行计算模型

* PRAM模型：SIMD-SM模型(共享存储的SIMD模型)，并行随机存取机器

  * 有一个集中的、容量无限大的存储器和一个指令控制器(所有处理器同一时间执行相同指令)，隐式同步计算
  * 全局指令、局部指令
  * 根据同时读、写的限制，分类：
    * PRAM-CRCW：并发读并发写
      * 仅允许写入相同数据， CPRAM-CRCW
      * 仅允许优先级最高的处理器写入：PPRAM-CRCW
      * 允许任意处理器自由写入：APRAM-CRCW（最后谁写成功是随机的）
    * PRAM-CREW：并发读互斥写
    * PRAM-EREW：互斥读互斥写
    * 计算能力比较：ppt24-25, log P倍模拟
  * 优缺点

* 异步APRAM模型

  * 每个处理器有其局部存储器、局部时钟、局部程序；无全局时钟，各处理器异步执行
  * 处理器通过SM通讯。需在并行程序里显式加入同步路障
  * APRAM的指令类型：全局读、全局写、局部操作、同步
  * 计算过程ppt29
  * 计算时间
  * 优缺点

* BSP模型

  * 块同步模型，异步MIMD-DM模型，支持消息传递系统，块内异步并行，块间显式同步
  * 模型参数：处理器数p(带存储器)、同步障时间L、带宽因子(选路器吞吐率)g
  * 计算过程：超级步，书p154，ppt33
  * 优缺点：计算和通讯分离、但不能做即时通讯

* logP模型

  * 分布存储的、点到点通讯的多处理机模型，实行隐式同步

  * 模型参数：网络延迟L，通讯额外开销o，通讯带宽g，处理器数p

    L和g反映了通讯网络的容量；参数含义参考书p156

  * 优缺点

  * BSP vs logP   ppt36



## 第六章 并行算法基本设计策略

#### 6.1 串行算法的直接并行化

* 设计策略描述

  * 方法描述：发觉现有串行算法里的并行性
  * 评注：不是所有串行算法都可直接并行化；一个好的串行算法不一定能并行化为一个好的并行算法

* 快排序算法的并行化

  * 串行算法（ppt7），选择第一个元素为主元； 理想T(n)=$\Theta(nlogn)$

  * PRAM-CRCW上的快排序算法(利用二叉排序树)

    SIMD-SM模型

    时间复杂度为O(lgn)

#### 6.2 从问题描述开始设计并行算法

* 方法描述：从问题本身出发，设计全新的并行算法

* 评注：

  * 挖掘问题的固有特性与并行的关系

  * 利用串的周期性的PRAM-CRCW算法是一个很好的范例

* 前缀和问题：ppt14-15 ：全新设计法、借用法(==思考==)

* 串匹配问题：KMP串匹配算法的并行化，书

* 有向环k着色算法的并行化

  * 3着色串行算法：难以并行化

  * 基本并行k着色算法（SIMD-EREW模型），ppt18

    用的是破对称技术，算法的正确性需要证明

    例子里把15色简化为6色；进一步：消去5,4,3

#### 6.3 借用已有算法求解新问题

* 设计方法描述

  * 找出求解问题和某个已解决问题之间的联系
  * 改造或利用已知算法应用到求解问题上

* **利用矩阵乘法求所有点对间最短路径**

  ==连通矩阵与邻接矩阵自乘问题？？==





## 第7章 并行算法常用设计技术

### 7.1 划分设计技术

#### 7.1.1 均匀划分技术

* ppt 4-6, 示例：MIMD-SM模型上的PSRS排序

#### 7.1.2 方根划分技术

* 示例：SIMD-CREW模型上的Valiant归并
  * 方根划分
  * 段间比较
  * 段内比较
  * 递归归并
* 处理器个数以及时间复杂度：p12

#### 7.1.3 对数划分技术

* 示例：PRAM-CREW上的对数划分并行归并程序
* 位序的定义

### 7.2 分治设计技术

#### 7.2.1 并行分治设计步骤

* 将输入划分成若干规模相等的子问题，然后并行地递归求解这些子问题

#### 7.2.2 双调归并网络

* 双调序列定义：书p195

### 7.3 平衡树设计技术

#### 7.3.1 设计思想

* 将算法计算过程映射到一棵平衡树上，以树叶结点为输入，由叶向根或由根向叶逐层进行并行处理。 
* 树每层计算以O(1)为理想代价 ，整体计算时间控制在树高度O(log n)。

#### 7.3.2 求最大值

* SIMD-TC（SM）上求最大值算法 ：例子及复杂度分析
* SIMD-CRCW上常数时间求最大值算法

#### 7.3.3 计算前缀和

* 问题定义
* 串行算法：时间为O(n)
* SIMD-TC上非递归算法

### 7.4 倍增设计技术

### 7.5 流水线设计技术

## 第14章 共享存储系统并行编程 OpenMP

### 14.1 ANSI X3H5共享存储模型

* 编程模型的作用
  * 规定程序的执行模型 ：SPMD, SMP 等。 
  * 如何表达并行性 DOACROSS, FORALL, PARALLEL, INDEPENDENT。 
  * 如何表达同步 ： Lock, Barrier, Semaphore, Condition Variables。 
  * 如何获得运行时的环境变量
* X3H5模型中并行语句规定
  * 并行块（工作共享构造），例子见ppt7，8
    * 并行块(psections ... end psections) 
    * 并行循环(pdo ... Endo pdo) 
    * 单进程(psingle ... End psingle) 
    * 可嵌套 
  * 非共享块重复执行；
  * 隐式路障、显式路障和阻挡操作； 
  * 共享/私有变量； 
  * 线程同步； 
    * 门插销(latch)：临界区 
    * 锁：test,lock,unlock 
    * 事件: wait,post,clear 
    * 序数(ordinal): 顺序

### 14.2 POSIX线程模型

* POSIX：可移植操作系统接口
* 线程的概念：ppt12，同一进程内线程的内存共享
  * 线程管理
  * 线程 互斥(锁) 与 同步（信号量):https://blog.csdn.net/zhangkunrun/article/details/38337201

### 14.3 OpenMP模型

#### 概述

* 共享存储体系结构上的编程模型，包含 **编译制导、运行库例程、环境变量**
* 支持增量并行化
* 不包含的性质：
  * 不是建立在分布式存储系统上的；
  * 不是在所有的环境下都是一样的； 
  * 不是能保证让多数共享存储器均能有效的利用

#### 编程风格

* 基于线程的并行编程模型

* 使用 Fork-Join并行执行模型

* ppt 30 例子 运行结果发现，在openmp里并行执行时反而比只有主线程执行时慢很多，且线程开的越多，那么每个线程速度越慢

  ![image-20210514214542024](D:\科大\大三下\并行计算\image\image-20210514214542024.png)

#### 编程简介

##### 编译制导

* 语句格式![image-20210514214824135](D:\科大\大三下\并行计算\image\image-20210514214824135.png)

* 作用域 

  * 静态扩展 ：文本代码在一个编译制导语句之后，被封装到一个结构块中。 
  * 孤立语句 ：一个OpenMP的编译制导语句不依赖于其它的语句 。 
  * 动态扩展 ： 包括静态范围和孤立语句。

  ppt33示例：for语句；critical语句；sections语句

##### 并行域结构

并行域中的代码被所有的线程执行

* 具体格式：
  * #pragma omp parallel [clause[[,]clause]…]newline 
  * clause= 
    *  if (scalar_expression) 
    * private (list) 
    * shared (list)  
    * default (shared | none) 
    * firstprivate (list) 
    * reduction (operator: list) 
    * copyin (list) 
* 共享任务结构
  * 并行for循环
  * 并行sections
  * 串行执行

##### for编译制导语句

* for语句指定紧随它的循环语句必须由线程组并行执行； 

* 语句格式 

  * #pragma omp for [clause[[,]clause]…] newline

  *  [clause]= 

    * Schedule(type [,chunk]) 

      schedule子句描述如何将循环的迭代划分给线程组中的线程； 

      * 如果没有指定chunk大小，迭代会尽可能的平均分配给 每个线程； 
      * type为static，循环被分成大小为 chunk的块，静态分配给线程； 
      * type为dynamic，循环被动态划分为大小为chunk的块 ，动态分配给线程； 
      * type为guided，采用启发式调度，每次分配给线程迭代次数不同，开始比较大，以后逐渐减小； 
      * type为runtime，允许在运行时确定调度类型。

    * ordered 

    * private (list) 

    * firstprivate (list) 

    * lastprivate (list) 

    * shared (list) 

    * reduction (operator: list) 

    * nowait

* 示例：ppt37

##### sections编译制导语句

* sections编译制导语句指定内部的代码被划分给线程组中的各线程； 

* 不同的section由不同的线程执行； 

* Section语句格式：

  ```c
  #pragma omp sections [ clause[[,]clause]…] newline 
  { 
  	[#pragma omp section newline]
      … 
      [#pragma omp section newline] … 
  } 
  ```

* clause= 

  * private (list) 
  * firstprivate (list) 
  * lastprivate (list) 
  * reduction (operator: list) 
  * nowait 

* 在sections语句结束处有一个隐含的路障，使用了 nowait子句除外。

##### single 编译制导语句

* single编译制导语句指定内部代码只有线程组中的一个 线程执行； 
* 线程组中没有执行single语句的线程会一直等待代码块 的结束，使用nowait子句除外； 
* 语句格式： #pragma omp single [clause[[,]clause]…] newline 
  * clause= 
    * private(list) 
    * firstprivate(list) 
    * nowait

##### 组合的并行共享任务结构

* parallel for编译制导语句
  * Parallel for编译制导语句表明一个并行域包含一个独 立的for语句； 
  * 语句格式 
    * #pragma omp parallel for [clause…] newline 
    * clause=
      * if (scalar_logical_expression) 
      * default (shared | none) 
      * schedule (type [,chunk]) 
      * shared (list) 
      * private (list) 
      * firstprivate (list) 
      * lastprivate (list) 
      * reduction (operator: list) 
      * copyin (list)
* parallel sections编译制导语句
  * parallel sections编译制导语句表明一个并行域包含单独的一个sections语句； 
  * 语句格式 
    * #pragma omp parallel sections [clause…] newline 
    * clause= 
      * default (shared | none) 
      * shared (list) 
      * private (list)
      * firstprivate (list) 
      * lastprivate (list) 
      * reduction (operator: list) 
      * copyin (list) 
      * ordered

##### 同步结构

* master 制导语句

  * 指定代码段只有主线程执行
  * 格式：\#pragma omp master newline 

* critical制导语句

  * 表明域中的代码一次只能执行一个线程；
  * 其他线程被阻塞在临界区；
  * 格式：#pragma omp critical [name] newline 

* barrier制导语句

  * barrier制导语句用来同步一个线程组中所有的线程； 
  * 先到达的线程在此阻塞，等待其他线程；
  * barrier语句最小代码必须是一个结构化的块； 
  * 语句格式 ：#pragma omp barrier newline

* atomic制导语句

  * atomic制导语句指定特定的存储单元将被原子更新； 
  * 语句格式 #pragma omp atomic newline
  * 一些要求：ppt54 （可以比较一下与临界区方法的性能)

* flush制导语句

  * flush制导语句用以标识一个同步点，用以确保所有的线 程看到一致的存储器视图； 
  * 语句格式 :#pragma omp flush (list) newline 
  * flush将在下面几种情形下隐含运行，nowait子句除外,ppt 55

* ordered制导语句

  * ordered制导语句指出其所包含循环的执行； 

  * 任何时候只能有一个线程执行被ordered所限 定部分； 

  * 只能出现在for或者parallel for语句的动态范 围中； 

  * 语句格式： #pragma omp ordered newline 

  * 示例

    ```c
    #pragma omp parallel for ordered schdule(static, 2) 
    for (i=0; i<10; i++) 
        #pragma omp ordered 
        printf("i=%ld\n", i);
    ```

##### threadprivate编译制导语句

* threadprivate语句使一个全局文件作用域的变量在并行域内变成每个线程私有； 
* 每个线程对该变量复制一份私有拷贝； 
* 语句格式: #pragma omp threadprivate (list) newline

##### 数据域属性子句

* private子句

  ![image-20210514231436753](D:\科大\大三下\并行计算\image\image-20210514231436753.png) 

* shared子句

  * shared子句表示它所列出的变量被线程组中所有的线程共享； 

  * 所有线程都能对它进行读写访问； 
  * 语句格式： shared (list) 

* default子句

  * default子句让用户自行规定在一个并行域的静态范围 中所定义变量的shared和private缺省性质； 
  * 语句格式： default (shared | none)  

* firstprivate子句

  * firstprivate子句是private子句的配合操作； 
  * 对变量做原子初始化； 
  * 语句格式： firstprivate (list) 

* lastprivate子句

  * lastprivate子句是private子句的配合操作； 
  * 将变量从最后的循环迭代或段复制给原始的变量； 
  * 语句格式： lastprivate (list)

* copyin子句

  * copyin子句用来为线程组中所有线程的threadprivate 变量赋相同的值； 
  * 主线程该变量的值作为初始值； 
  * 语句格式： copyin(list)

* reduction子句

  * reduction子句使用指定的操作对其列表中出现的变量 进行归约； 
  * 初始时，每个线程都保留一份私有拷贝； 
  * 在结构尾部根据指定的操作对线程中的相应变量进行归 约，并更新该变量的全局值； 
  * 语句格式： reduction (operator: list) 
  * ![image-20210514233228257](D:\科大\大三下\并行计算\image\image-20210514233228257.png)

#### 运行库例程与环境变量

* 环境变量 
  * OMP_SCHEDULE：只能用到for,parallel for中。它的值就是 处理器中循环的次数； 
  * OMP_NUM_THREADS：定义执行中最大的线程数； 
  * OMP_DYNAMIC：通过设定变量值TRUE或FALSE,来确定是 否动态设定并行域执行的线程数； 
  * OMP_NESTED：确定是否可以并行嵌套。

#### OpenMP计算实例

* 使用并行域并行化的程序
* 使用共享任务结构并行化的程序
* 使用private子句和critical部分并行化的程序
* 使用并行归约得出的并行程序
* OMP的优点和缺点
  * 优点 
    * 提供了一个可用的编程标准； 
    * 可移植性, 简单, 可扩展性； 
    * 灵活支持多线程, 具有负载平衡的潜在能力； 
    * 支持Orphan Scope, 使程序更具有模块化。 
  * 缺点 
    * 只适用于硬件共享存储型的机器； 
    * 动态可变的线程数使得支持起来困难



## 第15章 分布存储系统并行编程

#### 15.1 基于消息传递的编程

面向分布式机器结构

##### 消息传递库

最流行的是MPI和PVM

* PVM和MPI间的主要差别
  * PVM是一个自包含的系统, 而MPI不是. MPI依赖于支持它的平台提供对进程的管理和I/O功能. 而PVM本身就包含 这些功能. 
  * MPI对消息传递提供了更强大的支持. 
  * PVM不是一个标准, 这就意味着PVM可以更方便、更频繁地进行版本更新. MPI和PVM在功能上现在正趋于相互包含. 例如, MPI-2增 加了进程管理功能, 而现在的PVM也提供了更多的群集通信函数. 

##### 消息传递方式

* 关于通信模式, 用户需要理解的有三个方面:

  * 共有多少个进程? 
  * 进程间如何同步? 
  * 如何管理通信缓冲区? 
  * 现在的消息传递系统多使用如下三种通信模式: 
    * 同步的消息传递 (Synchronous Message Passing) 
    * 阻塞的消息传递 (Blocking Message Passing) 
    * 非阻塞的消息传递 (Nonblocking Message Passing) 

* ![image-20210521212415680](D:\科大\大三下\并行计算\image\image-20210521212415680.png)

  非阻塞模式本身也会带来一些额外开销: 

  * 作为临时缓冲区用的内存空间 
  * 分配缓冲区的操作 
  * 将消息拷入和拷出临时缓冲区 
  * 执行一个额外的检测和等待函数

* 消息传递的特点: 

  * 在消息传递模型中, 一个并行应用由一组进程组成, 每个进程的代码是本地的, 只能访问私有数据, 进程之间通过传递消息实现数据共享和进程同步. 
  * 优点: 用户可以对并行性的开发、数据分布和通信实现完全控制. 
  * 缺点: 
    * 要求程序员显式地处理通信问题, 如, 消息传递调用的位置, 数据移动, 数据复制, 数据操作, 数据的一致性等等. 
    * 对大多数科学计算程序来说, 消息传递模型的真正困难还在于显式的域分解, 也就是说, 将对相应数据的操作限定在指定的处理器上进行, 在每个处理器上只能看见整个分布数据的一部分.
    * 无法以渐进的方式、通过逐步将串行代码转换成并行代码而开发出来. 大量的散布在程序各处的域分解要求整个程序由串行到并行的转换一 次性实现, 而共享存储方法允许在现有的串行代码中插入并行说明从 而实现逐步转换.与之相比, 这是消息传递的一个明显的缺点. 

#### 15.2 MPI并行编程

##### 6个基本函数

* ![image-20210521213122694](D:\科大\大三下\并行计算\image\image-20210521213122694.png)

  ![image-20210521213145851](D:\科大\大三下\并行计算\image\image-20210521213145851.png)

* MPI进程是重型的单线进程. 它们拥有不同的地址空间. 因此, 一个进程不能直接访问另一个进程地址空间的中的变量. 进程间的通信用消息传递来实现. 

##### MPI消息

* 消息结构

  * 消息缓冲：消息的内容，由三元组<起始地址，数据个数，数据类型>标识
  * 消息信封：消息的接收/发送者即信的地址，由三元组<源/目标进程，消息标签，通信域> 标识 
  * 三元组的方式使得MPI可以表达更为丰富的信息，功能更强大

* 消息类型

  * 预定义类型：MPI支持异构计算(Heterogeneous Computing)，它指在不同计算机系统上运行程序，每 台计算可能有不同生产厂商，不同操作系统。 MPI通过提供预定义数据类型来解决异构计算中的互操作性问题，建立它与具体语言的对应关系。

    * 预定义附加类型：

      * MPI_BYTE：一个字节，8bit

      * MPI_PACK：实现传输地址空间不连续的数据项，打包

        MPI_Unpack:拆包

  * 派生数据类型：MPI引入派生数据类型来定义由数据类型不同且地址空间不连续的数据项组成的消息 

    * MPI_Type_vector, MPI_Type_structure

    * 派生数据类型可以用类型图来描述，这是一种通用的类型描述方 法，它是一系列二元组<基类型，偏移>的集合，可以表示成如下 格式：  {<基类型0,偏移0>，···，<基类型n-1,偏移n-1>}

      在派生数据类型中，基类型可以是任何MPI预定义数据类型，也 可以是其它的派生数据类型，即支持数据类型的嵌套定义。

      如图，阴影部分是基类型所占用的空间，其它空间可以是特意留 下的，也可以是为了方便数据对齐。

    * 数据类型

      ![image-20210521215845977](D:\科大\大三下\并行计算\image\image-20210521215845977.png)

      示例

      **MPI_Type_vector**

      ![image-20210521220049416](D:\科大\大三下\并行计算\image\image-20210521220049416.png)

      ![image-20210521220057387](D:\科大\大三下\并行计算\image\image-20210521220057387.png)

      **MPI_Type_struct**

      ppt39-41

* 消息标签

  * 为何需要：当发送者连续发送两个相同类型消息给同一个接收者，如果没有消息标签，接收者将无法区分这两个消息

    这段代码打算传送A的前32个字节进入X，传送B的前16个字节进 入Y。但是，尽管消息B后发送，但可能先到达进程Q，就会被第 一个接收函数接收在X中。使用标签可以避免这个错误

    添加标签使得服务进程可以对两个不同的用户进 程分别处理，提 高灵活性

* 通信域：进程组+通信上下文

  * 通信域(Communicator)包括进程组(Process Group)和通信上下文(Communication Context)等内容，用于描述通信进程间的通信关系。 

  * 通信域分为组内通信域和组间通信域，分别用来实现 MPI的组内通信(Intra-communication)和组间通信 (Inter-communication)。

  * 进程组是进程的有限、有序集。 有限意味着，在一个进程组中，进程的个数n是有限的，这里 的n称为进程组大小(Group Size)。 有序意味着，进程的编号是按0，1，…，n-1排列的

    一个进程用它在一个通信域(组)中的编号进行标识。组的大小和进程编号可以通过调用以下的MPI函数获得： MPI_Comm_size(communicator, &group_size) ，MPI_Comm_rank(communicator, &my_rank) 

  * 通信上下文：安全的区别不同的通信以免相互干扰 。通信上下文不是显式的对象，只是作为通信域的一部分出现 

  * 进程组和通信上下文结合形成了通信域 : MPI_COMM_WORLD是所有进程的集合

  * 管理通信域的函数：ppt48

  * 组间通信域是一种特殊的通信域，该通信域包括了两个 进程组，分属于两个进程组的进程之间通过组间通信域 实现通信。 

    一般把调用进程所在的进程组称为本地进程组，而把另外一个称为远程进程组。

* 消息状态

  * 消息状态(MPI_Status类型)存放接收消息的状态信息， 包括: 

    * 消息的源进程标识－－MPI_SOURCE 
    * 消息标签－－MPI_TAG 
    * 错误状态－－MPI_ERROR 
    * 其他－－包括数据项个数等，但多为系统保留的

  * 当一个接收者从不同进程接收不同大小和不同标签的消 息时，消息的状态信息非常有用。

    假设多个客户进程发送消息给服务进程请求服务，通过 消息标签来标识客户进程，从而服务进程采取不同的服务

##### 点对点通信

* MPI的点对点通信(‘Point-to-Point Communication )同时提供了阻塞和非阻塞两种通信机制 ，同时也支持多 种通信模式。 不同通信模式和不同通信机制的结合，便产生了非常丰富的点对点通信函数。 

  * 划分依据： (1)发送(接收)的数据是否缓存； (2)发送(接收)调用正确返回的时间点； (3)执行发送操作与接收调用启动的次序； (4)发送(接收)正确返回，其发送(接收)缓冲区是否可以覆盖(引用)； (5)发送数据是否到达接收缓冲区。

* 通信机制：阻塞和非阻塞通信机制的主要区别在于返回后的资源可用性。 

  * 阻塞通信返回的条件： 
    * 通信操作已经完成，表示消息已经发送或接收。 
    * 调用的缓冲区可用。若是发送操作，则该缓冲区可以被其它的操作更新；若是接收操作，该缓冲区的数据已经完整，可以被正确引用

* 通信模式：指的是缓冲管理，以及发送方和接收方之间的同步方式

  * 标准通信模式：是否对发送的数据进行缓冲由MPI的实现来决定，而不是由用户程序来控制。发送可以是同步的或缓冲的，取决于实现。 
    * 如果缓存数据，发送操作执行与接收操作是否启动无关。 数据缓存完毕，发送操作就可正确返回。  
    * 如果不缓存数据，只有当接收操作启动时且发送数据完全到达接收缓冲区后，发送操作才能返回。非阻塞发送可提前返回，但应有系统缓冲区支持。
  * 缓冲通信模式：缓冲通信模式的发送不管接收操作是 否已经启动都可以执行。 
    * 需要用户程序对通信缓冲区进行控制：事先申请一块足够大的缓冲区，通过MPI_Buffer_attch实现，通过 MPI_Buffer_detach来回收申请的缓冲区。 
    * 分阻塞和非阻塞，缓冲区使用方式同阻塞和非阻塞机制的规定。注意MPI的发送和接收缓冲区与系统缓冲区的 区别。
  * 同步通信模式：只有相应的接收过程已经启动，发送过程才正确返回。开始时不依赖接收操作是否启动。 
    * 同步发送返回时，表示发送缓冲区中的数据已经全部被系统缓冲区缓存，并且已经开始发送。 
    * 阻塞同步发送返回后，发送缓冲区可以被释放或者重新使用。
  * 就绪通信模式：只有在接收进程相应的接收操作已经开始时才能进行发送。 
    * 当发送操作启动而相应的接收还没有启动，发送操作将出错。就绪通信模式的特殊之处就是接收操作必须先于发送操作启动。 
    * 也分阻塞和非阻塞，缓冲区使用方式同阻塞和非阻塞机制的规定。

* 通信操作

  * 8种发送：MPI的发送操作支持四种通信模式，它们与阻塞属性一 起产生了MPI中的8种发送操作
  * 2种接收：阻塞接收和非阻塞接收

* 非阻塞的优势

  * 计算与通信重叠，双缓冲方案

  * 在阻塞通信的情况下，通信还没有结束的时候，处理器只能等待， 浪费了计算资源。 

    一种常见的技术就是设法使计算与通信重叠，非阻塞通信可以用来实现这一目的

    * 非阻塞通信中，双缓冲是一种常用的方法。 我们需要为X和Y各自准备两个单独的缓冲，当接收进程向缓冲 中放下一个X时，计算进程可能从另一个缓冲中读当前的X。 我们需要确信缓冲中的数据是否在缓冲，以及被更新之前使用

    * send_handle和revc_handle分别用于检查发送接收是否完成。 检查发送接收通过调用MPI_Wait(Handle, Status)来实现，它直 到Handle指示的发送或接收操作已经完成才返回 。 另一个函数MPI_Test(Handle, Flag, Status)只测试由Handle指 示的发送或接收操作是否完成，如果完成，就对Flag赋值True， 这个函数不像MPI_Wait，它不会被阻塞。

* 完成检测函数:  非阻塞通信的完成检测：非阻塞通信返回后并不意味着通信操作的完成，MPI还 提供了对非阻塞通信完成的检测，主要的有两种： MPI_Wait函数和MPI_Test函数。

* MPI_Sendrecv函数

  给一个进程发送消息，从另一个进程接收消息； 特别适用于在进程链（环）中进行“移位”操作，而避 免在通讯为阻塞方式时出现死锁

##### 群集通信

* 群集通信(Collective Communications)是一个进程组中的所有进程都参加的全局通信操作。 

  * 群集通信一般实现三个功能：通信、聚集和同步。 
    * 通信功能主要完成组内数据的传输 
    * 聚集功能在通信的基础上对给定的数据完成一定的操作 
    * 同步功能实现组内所有进程在执行进度上取得一致

* 群集通信，按照通信方向的不同，又可以分为三种：

  * 一对多通信：一个进程向其它所有的进程发送消息， 这个负责发送消息的进程叫做Root进程。 
  * 多对一通信：一个进程负责从其它所有的进程接收消息，这个接收的进程也叫做Root进程。 
  * 多对多通信：每一个进程都向其它所有的进程发送或者接收消息。

* 广播 ：MPI_Bcast(Address, Count, Datatype, Root, Comm)

  广播的特点 ：

  * 标号为Root的进程发送相同的消息给通信域Comm中的 所有进程。 
  * 消息的内容如同点对点通信一样由三元组标识。 
  * 对Root进程来说，这个三元组既定义了发送缓冲也定义 了接收缓冲。对其它进程来说，这个三元组只定义了接收缓冲

* 收集是多对一通信的典型例子，其调用格式下: MPI_Gather(SendAddress, SendCount, SendDatatype, RecvAddress, RecvCount, RecvDatatype, Root, Comm)

  收集的特点 

  * 在收集操作中，Root进程从进程域Comm的所有进程(包括它自已)接收消息。 
  * 这n个消息按照进程的标识rank排序进行拼接，然后存放在Root进程的接收缓冲中。 
  * 接收缓冲由三元组标识，发送缓冲由三元组标识，所有非Root进程忽略接收缓冲。

* 散播也是一个一对多操作，其调用格式如下: MPI_Scatter(SendAddress, SendCount, SendDatatype, RecvAddress, RecvCount, RecvDatatype, Root, Comm)

  散播的特点 	

  * Scatter执行与Gather相反的操作。 
  * Root进程给所有进程(包括它自已)发送一个不同的消息， 这n (n为进程域comm包括的进程个数)个消息在Root进 程的发送缓冲区中按进程标识的顺序有序地存放。 
  * 每个接收缓冲由三元组标识，所有的非Root进程忽略发送缓冲。 对Root进程，发送缓冲由三元组标识

* 全局收集多对多通信的典型例子，其调用格式如下： MPI_Allgather(SendAddress, SendCount, SendDatatype, RecvAddress, RecvCount, RecvDatatype, Comm)

   Allgather操作相当于每个进程都作为ROOT进程执行了一次 Gather调用，即每一个进程都按照Gather的方式收集来自所 有进程(包括自己)的数据。

* 全局交换也是一个多对多操作，其调用格式如下: MPI_Alltoall(SendAddress, SendCount, SendDatatype, RecvAddress, RecvCount, RecvDatatype, Comm)

  * 在全局交换中，每个进程发送一个消息给所有进程(包括 它自已)。 

  * 这n (n为进程域comm包括的进程个数)个消息在它的发送缓冲中以进程标识的顺序有序地存放。从另一个角度来看这个通信，每个进程都从所有进程接收一个消息，这n 个消息以标号的顺序被连接起来，存放在接收缓冲中。 
  * 全局交换等价于每个进程作为Root进程执行了一次散播操作。

* 同步功能用来协调各个进程之间的进度和步伐 。目前 MPI的实现中支持一个同步操作，即路障同步 (Barrier)。 

  * 路障同步的调用格式如下:  MPI_Barrier(Comm) 
  * 在路障同步操作MPI_Barrier(Comm)中，通信域Comm中的所有进程相互同步。 
  * 在该操作调用返回后，可以保证组内所有的进程都已经执行完了调用之前的所有操作，可以开始该调用后的操作

* 群集通信的聚合功能使得MPI进行通信的同时完成一定的计算。 

  * MPI聚合的功能分三步实现(前面介绍了两步) 

    * 首先是通信的功能，即消息根据要求发送到目标进程，目标进程也已经收到了各自需要的消息； 
    * 然后是对消息的处理，即执行计算功能；
    * 最后把处理结果放入指定的接收缓冲区。
    * MPI提供了两种类型的聚合操作: 归约和扫描

  * 归约的调用格式如下: MPI_Reduce(SendAddress, RecvAddress, Count, Datatype, Op, Root, Comm) 

    * 归约的特点 

      * 归约操作对每个进程的发送缓冲区(SendAddress)中的数据按给定的操作进行运算，并将最终结果存放在Root进程的接收缓冲区(RecvAddress)中。 
      * 参与计算操作的数据项的数据类型在Datatype域中定义，归约操作由Op域定义。 
      * 归约操作可以是MPI预定义的,也可以是用户自定义的。 
      * 归约操作允许每个进程贡献向量值，而不只是标量值，向量的长度由Count定义

    * ![image-20210521235828475](D:\科大\大三下\并行计算\image\image-20210521235828475.png)

      可自定义归约操作

  * 扫描的调用格式如下： MPI_scan(SendAddress, RecvAddress, Count, Datatype, Op, Comm) 

    扫描的特点 

    * 可以把扫描操作看作是一种特殊的归约，即每一个进程都对排在它前面的进程进行归约操作。 
    * MPI_SCAN调用的结果是，对于每一个进程i，它对进程 0,1,…,i的发送缓冲区的数据进行了指定的归约操作。 
    * 扫描操作也允许每个进程贡献向量值，而不只是标量值。向量 的长度由Count定义。

* 所有的MPI群集通信操作都具有如下的特点: 

  * 通信域中的所有进程必须调用群集通信函数。如果只有通信域中的一部分成员调用了群集通信函数而其它没有调用，则是错误的。 
  * 除MPI_Barrier以外，每个群集通信函数使用类似于点对点通信中的**标准、阻塞**的通信模式。也就是说，一个进程一旦结束了它所参与的群集操作就从群集函数中返回，但是并不保证其它进程执行该群集函 数已经完成。 
  * 一个群集通信操作是不是同步操作取决于实现。MPI要求用户负责保证他的代码无论实现是否同步都必须是正确的。 
  * 所有参与群集操作的进程中，Count和Datatype必须是兼容的。 
  * 群集通信中的消息没有消息标签参数，消息信封由通信域和源/目标定义。例如在MPI_Bcast中，消息的源是Root进程，而目标是所有进程(包括Root)

##### MPI扩展

* MPI-1假定所有的进程都是静态的，运行时不能增加和删除进程。MPI-2引入了动态进程的概念： 
  * MPI-1不定义如何创建进程和如何建立通信。MPI-2中的动态进程机制以可移植的方式(平台独立)提供了这种能力。 
  * 动态进程有利于将PVM程序移植到MPI上。并且还可能支持一 些重要的应用类型， 如Client/Server和Process farm。 
  * 动态进程允许更有效地使用资源和负载平衡。例如，所用节点数可以按需要减少和增加。 
  * 支持容错。当一个节点失效时，可以在另一个节点上创建一个 新进程运行该节点上的进程的工作。

##### 计算Pi的MPI程序

##### 小结



## 第16章 GPU

#### CUDA编程

* 函数限定符: `_device_   _global_  _host_`
* 变量限定符：`_shared_   _constant_  _shared_`
* 