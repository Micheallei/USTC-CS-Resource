### 第二章

2.1 插入排序

* 插入排序是两层循环，书p10

2.2 分析算法

2.3 设计算法

* 归并排序：（分治法）书p17,p19

  * 两个函数

    * MERGE():合并两个已排序序列

    * MERGE_SORT():主函数，递归调用



### 第四章

4.3 用代入法求解递归式

* 两步：

  1. 猜测解的形式
  2. 数学归纳法求出解中的常数，并证明解是正确的

* 多用代入法为递归式建立上界或下界（要求紧致）

* 但注意数学归纳法则需要边界条件的证明(归纳基础)

  解决思路：

  1. 放缩$n_0$（扩展边界条件）:即从$n_0=2，3$等开始
  2. 在先前的猜测中减去低阶项或加上一个值，但保持与所证的O(g(n))同阶

* 其他技巧：变量代换化为以前证过的形式

4.4 用递归树方法求解递归式

* **完全二叉树**：一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树

  * 高度：结点到叶结点的最长简单路径上边的数目

    树高h=$\lfloor lgn \rfloor$

    与深度是反过来的。

  * 层数：高度+1

  * 具有n个节点的完全二叉树的深度为 k=$\lfloor lgn \rfloor$

    结点的深度：从根节点开始，深度为0，依次往下
  
    树的深度：叶结点深度
  
* **严格二进制树：**每个节点正好有0或2个孩子

* 满二叉树：国内与国外定义不同：https://blog.csdn.net/threadrunner/article/details/8739847

  国外的满二叉树是指国内的严格二进制树

4.5 用主方法求解递归式





### 第六章 堆排序（Lec-3）

* 排序基本概念：

  * 排序算法的稳定性:不管输入数据是如何分布，对任意关键字相同的数据对象，
    在排序过程中是否能保持相对次序不变。如 2, 2+, 1，排序后若为1, 2+, 2 则该排序方法是不稳定的  
  * 内排序与外排序区分标准：排序过程是否全在内存进行
  * 排序的时间开销：数据比较次数、数据移动次数
  * 评价算法的标准
    1. 算法执行时间(时间开销是排序算法的最重要标准)
    2. 所需附加空间
    3. 算法本身复杂程度

* **简单排序：最坏时间复杂度$O(n^2)$，所需附加空间$\Theta(1)$**

  * 直接插入排序（稳定）：即插入排序，书p10
  * 冒泡排序：稳定
  * 简单选择排序（不稳定）：每趟从待排序的记录中选出关键字最小的记录，顺序放在已排序的记录序列末尾，直到全部排序结束为止。（序列5 8 5 2 9， 我们知道第一趟选择第 1 个元素 5 会与 2 进行交换，那么原序列中两个5的相对先后顺序也就被破坏了。）
  * 冒泡排序和直接插排的比较和移动都是O(n^ 2),简单选择排序比较是O(n^2),但移动只是O(n)(最坏情况)

* shell排序：用直接插入排序作为子过程；不稳定

  （元素之间有跳跃）

  * 是[插入排序](https://baike.baidu.com/item/插入排序/7214992)的一种又称“缩小增量排序”
  * 希尔排序是将待排序的数组元素 按下标的一定增量分组 ，分成多个子序列，然后对各个子序列进行直接插入排序算法排序；然后依次缩减增量再进行排序，直到增量为1时，进行最后一次直接插入排序，排序结束。

6.1 堆

* 二叉堆（是完全二叉树）分为：最大堆、最小堆
* 高度：结点到叶结点的最长简单路径上边的数目
* 层数：高度+1
* PARENT、LEFT、RIGHT函数

6.2 维护堆的性质

* MAX-HEAPIFY(A,i)

  先决条件：需要i节点为根节点的树的左右子树均为最大堆

  结果：i节点为根节点的树也成为最大堆

  时间复杂度：O(lgn)(与树高h=$\lfloor lgn \rfloor$有关)

6.3 建堆

* BUILD-MAX-HEAP(A):建立最大堆
* 循环不变量及其三段论证明（参见书p10）
  * 初始化
  * 保持
  * 终止
* 两结论
  1. 包含n个元素的堆高度为$\lfloor lgn \rfloor$
  2. 高度为h的堆最多包含 $\lceil \frac{n}{2^{h+1}} \rceil$个节点
* 所以BUILD-MAX-HEAP(A) 时间复杂度为O(n)

6.4 堆排序算法

* HEAPSORT(A):时间复杂度O(nlgn)

6.5 优先队列

* 用堆来实现最大/最小优先队列

* 最大优先队列需要支持的操作：(最小优先队列MAX换为MIN)

  以下时间复杂度均假设有n个元素

  * INSERT(S,x)：x插入集合S中

    MAX-HEAP-INSERT(A,key):O(lgn)时间

  * MAXIMUN(S):返回S中最大关键字的元素。

    对应函数HEAP-MAXIMUN(A), $\Theta(1)$时间

  * EXTRACT-MAX(S)：去掉并返回S中的具有最大关键字的元素

    对应函数HEAP-EXTRACT-MAX(A):O(lgn)时间

  * INCREASE-KEY(S,x,k):将元素x的关键字值增加到k(k>=x，否则为空操作)

    函数HEAP-INCREASE-KEY(S,x,k):注意需要维护大根堆，所以结点要不断和父节点比较，O(lgn)时间

    

### 第七章 快速排序

* 最坏时间复杂度$\Theta(n^2)$
* 期望时间复杂度$\Theta(nlgn)$
* 原址排序

##### 7.1 快速排序的描述

* 分治法思想

  分解、解决、合并(不需此步)

* 数组的划分PARTITION(A,p,r)是关键，详见书p95-96的图解,主元为A[r]

  时间复杂度:$\Theta(n)$

* 循环不变量

* 快速排序不稳定

##### 7.2 快速排序的性能

* 快速排序运行时间依赖于划分是否平衡
* 最坏：每次划分为n-1和0，此时$\Theta(n^2)$
* 最好：可能的最平衡划分：每次划分$\lfloor n/2\rfloor$和$\lceil n/2\rceil-1$,此时$\Theta(nlgn)$
* 平衡的划分：常数比例的划分时，总是$O(nlgn)$

##### 7.3 快速排序的随机化版本

* 就是在PARTITION函数里，开始随机取数组中一个数与A[r]交换来作为主元

  实际数组排列顺序的随机性本身就保证了这种随机性，并不需要显示随机交换

##### 7.4 快速排序分析

* 本节从递归式入手计算分析
* 最坏情况：$\Theta(n^2)$
* 期望运行时间：O(nlgn),书上和ppt(p82-84)上两种证明

##### 7.5 快排与堆排序比较（ppt p88补充章节）





### 第8章 线性时间排序

##### 偏序与全序的概念

偏序： 设R是非空集合A上的关系，如果R是自反的，反对称的，和传递的，则称R是A上的偏序关系。
偏序的定义：设R是集合A上的一个二元关系，若R满足：
Ⅰ 自反性：对任意x∈A，有xRx；
Ⅱ 反对称性（即反对称关系）：对任意x,y∈A，若xRy，且yRx，则x=y；
Ⅲ 传递性：对任意x, y,z∈A，若xRy，且yRz，则xRz。 则称R为A上的偏序关系。

全序：如果R是A上的偏序关系，那么对于任意的A集合上的 x,y，都有 x <= y，或者 y <= x，二者必居其一，那么则称R是A上的全序关系。
全序的定义：设集合X上有一全序关系，如果我们把这种关系用 ≤ 表述，则下列陈述对于 X 中的所有 a, b 和 c 成立：
如果 a ≤ b 且 b ≤ a 则 a = b (反对称性)
如果 a ≤ b 且 b ≤ c 则 a ≤ c (传递性) a ≤ b 或 b ≤ a (完全性)
注意：完全性本身也包括了自反性。 所以，全序关系必是偏序关系



##### 8.1 排序算法的下界

* 比较排序：归并、堆、快速排序等

* 决策树模型

* 具有n个节点的完全二叉树的深度为 k=$\lfloor lgn \rfloor$

* 结点的深度：从根节点开始，深度为0，依次往下

  树的深度：叶结点深度

* 最坏情况下，任何比较排序算法都要做$\Omega(nlgn)$次比较

* 堆排序和归并排序都是渐进最优的比较排序算法

##### 8.2 计数排序

* n个输入元素，值均为[0,k]上一个整数；
* 一般时间复杂度为$\Theta(k+n)$；k=O(n)时，排序时间复杂度$\Theta(n)$

* 计数排序是稳定的

##### 8.3 基数排序

* n个d位数，每一个数位有k个可能取值，RADIX-Sort用的稳定排序方法耗时$\Theta(n+k)$,则其可以在$\Theta(d(n+k))$时间内排好序
* 引理8.4
  1. b<$\lfloor lgn \rfloor$,取r=b,得时间代价$\Theta(n)$
  2. b>= $\lfloor lgn \rfloor$,取r=$\lfloor lgn \rfloor$得到时间代价$\Theta(bn/lgn)$
* 但基数排序(所用的计数排序不是原址排序)和快速排序的选择要考虑具体实现、底层硬件、输入数据特征等

##### 8.4 桶排序

* 假设数据服从均匀分布：平均时间代价为O(n)
* 数据均匀、独立分布在[0,1)区间
* n个数据排序：将[0,1)区间分为n等份，称为桶
* 对每个桶排序，最后依次输出
* 平均排序时间代价计算见书p113



### 第9章 中位数和顺序统计量

* 第i个顺序统计量：集合中第i小的元素

* 最小值、最大值、中位数（下中位数$\lfloor (n+1)/2 \rfloor$、上中位数$\lceil (n+2)/2 \rceil$）

  中位数分n为奇偶的情况。本书一般用下中位数

* 本章讨论从一个由n个互异元素组成的集合中选择第i个顺序统计量

##### 9.1 最小值和最大值

* 找min或max: 最好即是n-1次比较

* 同时找到最小和最大：$\lceil \frac{3n}{2} \rceil -2$(不论奇偶)

  偶为 3n/2-2; 奇为3(n-1)/2

##### 9.2 期望为线性时间的选择算法

* RANDOMIZED-SELECT算法
  * 最坏$\Theta(n^2)$; 期望$\Theta(n)$



##### 9.3 最坏情况为线性时间的选择算法

* 步骤：1-5（书p123）
* T(n)=O(n)



### 第12章 二叉搜索树（ppt lec5）

##### 12.1 什么是二叉搜索树

* 定义：包含属性：key，left，right，p

  * 左子树关键字不超过根，右子树关键字不低于根
  * 大部分操作最坏运行时间与树高成正比

* 中序遍历（左根右）按序输出各结点。 先序遍历、后序遍历

  INORDER-TREE-WALK(x)中序遍历，$\Theta(n)$

##### 12.2 查询二叉搜索树

* 高度为h的树，本节所有操作均需$O(h)$

* 查找：TREE-SERACH(x,k)的递归和迭代版本p163

* 最大关键字元素和最小关键字元素：一直往右/左走

  TREE-MINIMUM(x)，TREE-MAXIMUM(x)

* 后继和前驱

  TREE-SUCCESSOR（x）：后继：书p164

  TREE-PREDECESSOR(x):前驱，ppt18

##### 12.3 插入和删除

* 插入：TREE-INSERT(T,x)，O(h)

* 删除：分情况讨论，四种情况：见书p166-p167

  1. z无孩子或只有右孩子
  2. z只有左孩子
  3. z有左右孩子且z的后继y为z的右孩子
  4. z有左右孩子且z的后继y不为z的右孩子（注意3，4里y一定无左孩子且在z的右子树中）

  * O(h)
  * TREE-DELETE（T,z）,主函数
  * TRANSPLANT(t,u,v):用v来替换u这个结点(只是与u的双亲作了联系，并未动u，v的孩子)

##### 12.4 随机构建二叉搜索树（不考）

* 二叉搜索树高度$h>=\lfloor lgn \rfloor$
* n个关键字的一颗随机构建二叉搜索树为按随机次序插入这些关键字到一颗初始的空树中而生成的树，输入关键字的n!个排列中每个都是等可能
* 定理12.4：一颗有n个不同关键字的随机构建二叉树期望高度为O(lgn)

##### ppt补充

* 二分检索：如折半查找、Fibonic查找(ppt22页补充笔记)
* 二分检索的过程，可以用一个二叉树来表示，即二分检索树
* 二分检索算法：ppt21。 变式：不是对半分情况



### 第 13 章 红黑树

* 最坏情况下基本动态集合操作的时间复杂度为$O(lgn)$

##### 13.1 红黑树的性质

* 树中结点属性：color,key,left,right,p

  把带关键字的结点视为树的内部结点

* 红黑性质：5条

* 哨兵结点T.nil

* 结点的黑高：bh(x)，不包括该结点

  红黑树的黑高为其根结点的黑高

* 引理13.1：一棵有n个内部结点的红黑树高度至多为$2lg(n+1)$

* TREE-SERACH(x,k)

  TREE-MINIMUM(x)，TREE-MAXIMUM(x)

  TREE-SUCCESSOR（x）：后继：书p164

  TREE-PREDECESSOR(x):前驱，ppt18

  以上算法可在红黑树上O(lgn)时间内运行，代码同12章

##### 13.2 旋转

* 基于x左旋：x变为其右孩子的左儿子
* 基于y右旋：y变为其左孩子的右儿子
* LEFT-ROTATE(T,x):假定x的右孩子不是叶结点
* RIGHT-ROTATE(T,x)与左旋操作代码对称
* 两个算法都可以在O(1)内完成，因为只做了指针改变

##### 13.3 插入

* RB-INSERT(T,z): 想普通二叉搜索树那样插入一个结点z，并把它着红色

* RB-INSERT-FIXUP(T,z)：对结点重新着色并旋转

* 对照代码理解书上所讲的三种case以及循环不变式的保持

  总而言之，循环只在case 1时反复，一旦进入case 2或case 3，则执行完当次循环后循环结束

* 时间: O(lgn)

##### 13.4 删除

* RB-TRANSPLANT(T,u,v)

  与12章差不多，主要区别在于NIL的不同

* RB-DELETE(T,z)

  与12章差不多，主要区别在于

  * 结点y的维护
    * y初始颜色的存储
    * y始终为从树中删除的结点(第一行)或移动至树内的结点(第9行)

  * 结点x的维护

    * x始终指向y的唯一子节点或指向哨兵T.nil（当y无子节点时）

      其赋值语句在第4，7，11行，可参考纸质书p184和p167笔记

      且需要注意到，当处于p167的c，d两种情况时，可根据y的颜色来显而易见的看出x是不是T.NIL（y为红色时，一定是；y为黑色时，x若为黑色则一定是；但也可x为红色，不过此时调用RB-DELETE-FIXUP(T,x)循环都不用进去就可以修正了）

* RB-DELETE-FIXUP(T,x)

  主要四种情况分类理清楚即可，参考ppt99页的实例

  四种case的运行情况参考ipad书p185页

  * case1： x兄弟w为红

  * case2 ： x兄弟w为黑，且w的两儿子都黑

  * case3： x兄弟w为黑，且 w的左孩子为红，右孩子为黑

  * case4： x兄弟w为黑，且 w右孩子为红

  * case1 最多进一次，一旦进入后，无论之后走case 2 还是 case 3/4,都会退出循环

    直接case 2，有循环

    一旦进入case3 或4，则必退出循环

* 时间复杂度O(lgn)



### 第 14 章 数据结构的扩张

##### 14.1 动态顺序统计

* 对无序集合，可以在O(n)内确定任何的顺序统计量
* 修改红黑树，使得O(lgn)内确定任何顺序统计量
* 顺序统计树：新增属性x.size，哨兵结点此值为0
* 秩：集合线性序中的位置：即中序遍历树时输出的位置
* 查找具有给定秩的元素
  * OS-SELECT(x,i)
  * O(lgn）
* 确定一个元素的秩
  * OS-RANK(T,x)
  * O(lgn）
* 对子树规模的维护
  * 增加的size属性需要在插入和删除操作里维护，并且不改变基本操作的渐进运行时间
  * 增加的代码较少，参见书即可

##### 14.2 如何扩张数据结构

* 扩张数据结构四步
  * 选择一种基础数据结构
  * 确定基础数据结构中要维护的附加信息(如x.size，当然也可以是指针类信息而非具体数据)
  * 检验基础数据结构上的基本修改操作能否维护附加信息
  * 设计一些新操作
* 对红黑树的扩张
  * 定理14.1
  * 感觉证明里没有太严格的说明
  * 本节作业里维护结点深度有点问题？？

##### 14.3 区间树

* 闭区间、开区间、半开区间
* 低端点i.low, 高端点i.high
  * 两个区间重叠的定义
  * 区间三分律
* 区间树：
  * 每个元素x包含一个区间x.int
  * 支持的操作
    * INTERVAL-INSERT(T,x)
    * INTERVAL-DELETE(T,x)
    * INTERVAL-SEARCH(T,i)
  * 四步走
    * 基础数据结构：x.int, 以区间低端点作为关键字
    * 附加信息： x.max:以x为根的子树中所有区间的端点的最大值
    * 对信息的维护
    * 设计新的操作：
      * INTERVAL-SEARCH(T,i)： 只需O(lgn)
      * 定理14.2

### 第15章 动态规划

##### 概述

* 适用于动态规划求解的问题的两个关键特征

  * 最优子结构（书p206）

    最优子结构性质：问题的最优解由相关子问题的最优解组合而成，这些子问题可以独立求解

    （全局最优，一定局部最优）

  * 子问题重叠：不同子问题具有公共的子子问题

* 常用来求解最优化问题

* 最优化问题

  * 每个最优化问题包含一组约束条件和一个优化函数
  * 可行解、最优解
  * 优化问题实例
  * 最优性原理：过程的最优决策序列具有如下性质：无论过程的初始状态和初始决策是什么，其余的决策必须相对于初始决策所产生的状态构成一个最优决策序列（即无论过去决策如何，只能从当前情况去找当前最优解）
  * 判断所给问题是否满足最优性原理(ppt lec06-10页)

* 设计动态规划算法的4个步骤

  1. 刻画一个最优解的结构特征(此步最难、最关键，即要确定最优子结构)
  2. 递归地定义最优解的值
  3. 计算最优解的值，通常采用自底向上的方法
  4. 利用计算出的信息构造一个最优解(此时需在第3步里维护一些额外信息)



##### 15.0 多段图(还需看ppt lec06-12页开始，未总结)

* 多阶段决策过程
* 向前处理法
* 向后处理法

##### 15.1 钢条切割

* 长度为n英寸的钢条共$2^{n-1}$种不同的切割方案（或按长度非递减顺序切割，见书p205底部注释）

* 递归式1:书15.1式（205页）

* 1的简化版本：递归式2：书15.2式（206页）

* 自顶向下递归实现

  CUT-ROD(p,n)

  运行时间$T(n)=2^n$

* 动态规划方法求解最优钢条切割问题

  * 主要思想是空间换时间， 保存子问题的解，再次需要时只需查找

  * 两种实现方法：$\Theta(n^2)$

    * 带备忘的自顶向下法

      MEMOIZED-CUT-ROD(p,n)

      MEMOIZED-CUT-ROD-AUX(p,n,r)

    * 自底向上法（比前者的时间复杂性函数有更小的系数）

      BOTTOM-UP-CUT-ROD(p,n)

* 子问题图

* 重构解：在求最优收益基础上，再保存对应切割方案

  EXTENDED-BOTTOM-UP-CUT-ROD(p,n)

  PRINT-CUT-ROD-SOLUTION(p,n)



##### 15.2 矩阵链乘法

* 完全括号化的矩阵乘积链：是单一矩阵，或是两个完全括号化的矩阵乘积链的积，且已外加括号

* 两个矩阵相乘的标准算法：MATRIX-MULTIPLY(A,B), 需要做乘法 pqr次 (A:p * q, B:q * r)

* 矩阵链乘法问题：给定n个矩阵的链，求完全括号化方案，使得计算乘积$A_1A_2...A_n$所需标量乘法次数最少

* 计算括号化方案的数量：递归公式15.6结果为$\Omega(2^n)$

  卡塔兰数的应用：https://blog.csdn.net/adminabcd/article/details/46672759

  * 完全括号化方案、n个结点的二叉树个数、n个值入栈的出栈序列等问题

* 应用动态规划方法：四步走
  * 最优括号化方案的结构特征：分析得出问题的最优子结构
  
  * 一个递归求解方案：式15.7(书213)；m[i,j]和s[i,j]
  
  * 计算最优代价；通常自底向上的方法
  
    MATRIX-CHAIN-ORDER(p)
  
    运行时间为$\Theta(n^3)$
  
    但还需$\Theta(n^2)$内存空间
  
  * 构造最优解：即利用s[i,j]数组输出最优括号化方案
  
    PRINT-OPTIMAL-PARENS
  
    思考：写成非递归？？



##### 15.3 动态规划原理

* 适于动态规划求解的问题的两要素

  * 最优子结构

    * p216四点：通用模式(蓝色勾)

    * 保持子问题空间尽可能简单

    * 对不同问题领域，最优子结构的不同体现在

      1. 原问题的最优解中涉及多少个子问题
      2. 在确定最优解使用哪些子问题时，我们需要考察多少种选择

    * 可以用子问题的总数和每个子问题需要考察多少种选择这两个因素的乘积来粗略分析动态规划算法的运行时间

    * 也可用子问题图来做分析

      每个顶点对应一个子问题；该子问题需考察的选择数对应该顶点的出度

    * 原问题最优解的代价通常是子问题最优解的代价加上由此次选择直接产生的代价

  * 微妙之处

    * 无权最短路径问题：有最优子结构

    * 无权最长路径问题：无最优子结构

    * 两者区别在于：子问题是否相关（最短路径里不相关）

      子问题无关：同一个原问题的一个子问题的解不影响另一个子问题的解

  * 重叠子问题

    * 问题的递归算法会反复求解相同的问题

    * 区别：分治算法里在递归每一步通常生成全新的子问题

    * 基于递归式的矩阵链乘法伪代码

      RECURSIVE-MATRIX-CHARIN（）

      T(n)=$\Omega(2^n)$

  * 重构最优解：学会利用表来存储对每个子问题所做的选择

  * 备忘：自顶向下策略

    * 为每个子问题维护一个表项，遇到相同子问题，则查表解决

    * MEMOIZED-MATRIX-CHAIN(p)

      LOOKUP-CHAIN()

    * 一般而言，自底向上算法比自顶向下的备忘算法快一个常量系数(都是O($n^3$)),因为前者无递归调用的开销，表维护开销也更小；

    * 但是，若子问题空间中某些子问题完全不必求解，则备忘方法更优，因为它只会求解那些绝对必要的子问题



##### 15.4 最长公共子序列

* 相似度的定义：1,2,3种

* 最长公共子序列(LCS)问题

  * 子序列
  * 公共子序列

* 步骤：

  1. 刻画最长公共子序列的特征

     * 前缀
     * LCS的最优子结构：定理15.1

  2. 一个递归解

     15.9式

     注意到在递归公式中，通过限定条件限定了需要求解哪些子问题

  3. 计算LCS的长度

     算法LCS-LENGTH(X,Y):  (X:m项，Y:n项)

     * c[i,j]存$X_i,Y_j$的LCS长度
     * b[i,j]存表项对应所选择的子问题最优解，用带方向的箭头表示
     * 算法按行主次序计算
     * 时间:$\Theta(mn)$
     * 图15-8:例子

  4. 构造LCS

     PRINT-LCS(b,X,i,j)打印出最长子序列

     * 运行时间$O(m+n)$

  5. 算法改进

     * 去掉表b：但表c仍需$\Theta(mn)$空间
     * 若只需计算LCS的长度，而不需重构该序列，则只用一行多一点的空间即可

##### 15.5 最优二叉搜索树

* 最优二叉搜索树问题：n个关键字ki(已排序，为内部结点)、n+1个伪关键字di(叶结点)，各有一个搜索频率pi/qi
* 注意二叉搜索树的度为0或2
* 期望搜索代价：式15.11，
* 目标：构造期望搜索代价最小的二叉搜索树
  * 最优二叉搜索树不一定高度最矮
  * 概率最高的关键字也不一定出现在二叉搜索树的根节点
* n个内部结点的严格二叉树数量为指数级：参见书228第二自然段
* 动态规划法求解
  * 最优二叉搜索树的结构
    * 空子树细节：只含一个伪关键字
  * 递归算法
    * 子问题域: e[i,j]  ,$i>=1,j<=n,且j>=i-1$
    * w(i,j)
    * 递归公式：15.14
    * root[i,j]保存根节点$k_r$下标
  * 计算最优二叉搜索树的期望搜索代价

### 第16章 贪心算法

##### 概述

* 总是做出局部最优的选择，希望能导致全局最优解

##### 16.1 活动选择问题

* 活动、兼容、开始时间、结束时间
* 活动已按结束时间单调递增排序
* 活动选择问题的最优子结构

  * $S_{ij}:a_i结束后开始，且在a_j开始前结束的活动集合$
  * 递归式16.2
* 贪心选择

  * $S_k:在a_k结束后开始的任务集合$
  * 定理16.1：考虑任意非空子问题$S_k$,令$a_m是S_k$中结束时间最早的活动，则$a_m$在$S_k$的某个最大兼容活动子集中
* 可以自顶向下计算，每次选择一个活动放入最优解
  
* 递归贪心算法
  * 结束时间相同的活动可以任意排列（此时作贪心选择也可任选其一）
  * 虚拟活动$a_0$
  * RECURSIVE-ACTIVITY-SELECTOR(s,f,k,n)
  * 变式：考虑问题按开始时间从小到大排序，则每次贪心选择开始时间最晚的那个活动->与书上所讲原理、证明一致
  * 运行时间$\Theta(n)$,不过若活动未排序，则排序还需$O(nlgn)$
* 迭代贪心算法
  * 尾递归 容易转化为迭代形式
  * GREEDY-ACTIVITY-SELECTOR(s,f)
  * $\Theta(n)$



##### 16.2 贪心算法原理

* 一般设计方法

  * 将最优化问题转化为这样的形式：对其作出一次选择后，只剩下一个子问题需要求解
  * 证明作出贪心选择后，原问题总是存在最优解，即贪心选择总是安全的
  * 证明作出贪心选择后，剩余的子问题满足性质：其最优解与贪心选择组合即可得到原问题的最优解，这样就得到了最优子结构

* 可用贪心算法的问题的性质；

  * 贪心选择性质：通过作出局部最优选择来构造全局最优解
    * 需证明每个步骤做出贪心选择能生成全局最优解
    * 多考虑对输入进行预处理或合适的数据结构来提高贪心选择的效率
  * 最优子结构
    * 一个问题的最优解包含其子问题的最优解
    * 主要需证明将子问题的最优解与贪心选择组合在一起就能生成原问题的最优解

* 贪心vs动态规划

  * 0-1背包问题：只能拿或不拿
  * 分数背包问题：可按单位重量拿走物品
  * 后者可用贪心策略，前者不能，前者可用动态规划

##### 16.3 赫夫曼编码

* 有效压缩数据

* 二进制字符编码、码字、定长编码、变长编码

* 前缀码

  * 前缀码的解码：可采用一种二叉树来表示，叶结点为给定的字符，字符的二进制码字为从根节点到该字符叶结点的简单路径表示，左子树为0,右子树为1
  * 编码树不是二叉搜索树

* 文件的最优编码方案总是对应一棵满二叉树，即每个非叶节点都有两个孩子节点，此时若有n个叶节点，则一定有n-1个内部结点

* 代价B(T)的定义：16.4式

  参考书245页后补充的一页笔记

  * 加权外部路径长度：E

  * k进制编码则需要求解E最小的k叉树

    * 特例：Huffman编码(二进制码)为E最小的二叉树

    * 一般而言，需要满足 (k-1)|(n-1)，（n为字符个数，k为进制，即n-1能被k-1整除），若不满足此要求，需添加虚拟节点(权值为0)

      此时，只需每次取权值最小的k个结点来合并即可

* 构造赫夫曼编码

  * 理解清楚什么是优先队列：见第六章

    其只是一种定义，而第六章是用堆来实现优先队列

  * 堆里有关算法只涉及数组，左右孩子的使用是HUFFMAN(C)算法中为了构建最后的二叉树而引入的

  * HUFFMAN编码不唯一，比如每次取的最小两个结点x,y,谁作为左子树都可以，代价相同，但编码不同

  * 运行时间$O(nlgn)$

    * 若改为van Emde Boas树：$O(nlglgn)$
    * 若按数据结构上所讲用一般数组：O(n^2)

* 赫夫曼算法的正确性

  需证明最优前缀码问题具有贪心选择和最优子结构性质

  参见16.2节**一般设计方法**一栏

  * 引理16.2解决了：

    * 将最优化问题转化为这样的形式：对其作出一次选择后，只剩下一个子问题需要求解(子问题即引理16.3中所述的字母表C'的编码树求解)
    * 证明作出贪心选择后，原问题总是存在最优解，即贪心选择总是安全的

  * 引理16.3解决了：

    证明作出贪心选择后，剩余的子问题满足性质：其最优解与贪心选择组合即可得到原问题的最优解，这样就得到了最优子结构

  * 所以得到定理16.4：HUFFMAN过程会生成一个最优前缀码





### 第17章 摊还分析

17.1

17.2

17.3



ppt lec06 237页开始的分治法应用





### 第19章 斐波那契堆

##### 概述

* 可合并堆：是支持以下5种操作的一种数据结构，见书

  * MAKE-HEAP():创建和返回一个新的不含任何元素的堆
  * INSERT(H,x)
  * MINIMUN(H)
  * EXTRACT-MIN(H)
  * UNION($H_1,H_2$)

* 斐波那契堆额外的操作

  * DECREASE-KEY(H,x,k)
  * DELETE(H,x)

* 时间复杂度分析图：书p290，ppt p142

  但注意斐波那契堆都是分析的摊还代价

* 理论和实际的斐波那契堆

* 二项堆和斐波那契堆search操作都低效

##### 19.1 斐波那契堆结构

* 斐波那契堆是一系列具有最小堆性质的有根树集合
* 指针：p,child,left,right,即兄弟节点间为环形的双向链表，称为他们父结点的孩子链表。都有指向父结点的指针，每个结点只能指向其某一个孩子
* 环形双向链表的好处：书p292第二段
* 特殊值：x.degree(孩子数目), x.mark
* 最小结点：H.min(多个最小取任意一个，空则为NIL)
* 根链表也是环形双向链表
* H.n ：H中当前结点数目
* 势函数：式19.1
* 在一个n个结点的斐波那契堆中任何结点的最大度数的上界D(n)

##### 19.2 可合并堆操作

* 创建一个新的斐波那契堆：MAKE-FIB-HEAP(),摊还代价O(1)

* 插入一个结点FIB-HEAP-INSERT(H,x)

  直接加入到根链表中，修改相应指针即可，算法里没有实际给出指针的修改(8-9行)

  摊还代价O(1)

* 寻找最小结点：H.min即是。O(1)

* 两个斐波那契堆的合并FIB-HEAP-UNION($H_1,H_2$) ,O(1)

* 抽取最小结点

  * 主函数FIB-HEAP-EXTRACT-MIN(H)
  * 合并H的根链表：调用CONSOLIDATE(H)
    * 两步走：找根链表中两个有相同度数的根x，y( y.key>=x.key)
    * 把y链接到x。调用FIB-HEAP-LINK(H,y,x)
  * 摊还代价O(D(n))
  * 参考书p295的图
  * 循环不变式分析

##### 19.3 关键字减值和删除一个结点

* 关键字减值
  * O(1)
  * FIB-HEAP-DECREASE-KEY(H,x,k)
    * 子函数CUT(H,x,y)和CASCADING-CUT(H,y)
  * 势的分析
* 删除一个结点
  * O(D(n))
  * FIB-HEAP-DELETE(H,x)

##### 19.4 最大度数的界

* FIB-HEAP-EXTRACT-MIN(H)和FIB-HEAP-DELETE(H,x)摊还时间为$O(lg n)$
* 上述结论成立需证明如下
  * 具有n个结点的斐波那契堆中任意结点度数的上界D(n)为O(lgn)
  * 引理19.1, 19.2，19.3，19.4，19.5



### 第21章 用于不相交集合的数据结构

##### 21.1 不相交集合的操作

* 代表
* 三个函数 ：MAKE-SET(x),  UNION(x,y),  FIND-SET(x)
* 分析运行时间的2个参数 ： n(MAKE-SET操作次数)，m（三个操作总次数）
* 一个应用：确定无向图的连通分量
  * CONNECTED-COMPONENTS(G)
  * SAME-COMPONENT(u,v)
  * 在具体实现中，图和不相交集的数据结构的表示需要互相引用

##### 21.2 不相交集合的链表表示

* 每个集合为一个链表，有head和tail指针。 链表中每个对象包含一个集合成员，一个next指针，一个返回到集合的指针。 代表为head所指节点

* MAKE-SET(x),  FIND-SET(x) 均只要O(1)

* UNION(x,y)：简单拼接，则与y的链表长度成线性关系

  所以能很容易得到一个$\Theta(n^2)$的操作序列

* 加权合并启发式策略：每次把短链表作为y

  需维护表的长度

  m个操作序列共需$O(m+nlgn)$时间( 定理21.1)

##### 21.3不相交集合森林

* 每个集合用一棵树表示，树根为代表，每个节点有x.p, x.rank
* 按秩合并、路径压缩来改进运行时间
* 伪代码：见书p329-330
* 时间分析：单独使用、合并使用，见书p330



### 第 22 章 基本的图算法

* G=(V,E), |V|为结点数，|E|为边数

##### 22.1 图的表示

* 针对无向图和有向图，均有两种表示：
  * 邻接链表（表示稀疏图时有优势）
    * 存储空间$\Theta(V+E)$
    * 可修改后表示权重图，即每条边有其权重
    * 缺陷：无法快速判断一条边（u,v）是否是图中的一条边：需顺序查找adj[u]的链表
  * 邻接矩阵（稠密图优势）
    * 可快速判断任意两个结点间是否有边相连
    * 无向图里是对称矩阵

##### 22.2 广度优先搜索

* Prim最小生成树算法和Dijkstra单源最短路径算法的基础

* 能计算源到每个可到达结点距离最少的边数，并生成广度优先搜索树

* 无向图/有向图都适用

* 颜色定义

  * 白色：未入队
  * 灰色：队列中
  * 黑色：已出队并探索完其邻接链表

* 算法:BFS(G,s), 复杂度$O(V+E)$， 用邻接矩阵则为$O(V^2)$

* 最短路径

  * 引理22.1， 22.2，22.3
  * 推论22.4
  * 广度优先搜索的正确性定理22.5

* 广度优先树：

  * 图G的前驱子图$G_{\pi}$是一棵广度优先树

  * 是连通的

  * $|E_{\pi}|=|V_{\pi}|-1$

  * $|E_{\pi}|$中的边称为树边

  * 引理22.6

  * 打印最短路径上的所有结点

    PRINT-PATH(G,s,v)

##### 22.3 深度优先搜索

* 前驱子图的定义：与广度优先的区别

  深度优先搜索的前驱子图形成一个由多棵深度优先树构成的深度优先森林

  森林$|E_{\pi}|$中的边称为树边

* 结点仍有白、灰、黑

* 所有深度优先树不相交

* 每个结点的时间戳：v.d, v.f分别表示该结点第一次发现以及该结点搜索完成时的时间

  u.d前u为白色， u.d和u.f间为灰色，u.f后为黑色

* DFS(G)，DFS-VISIT(G,u)

  时间复杂度$\Theta(V+E)$

* 深度优先搜索的性质

  * 结点发现时间和完成时间有括号化结构

    括号化定理22.7

    推论22.8：后代区间的嵌套

  * v是u的后代 <=> v在u为灰色的时间里被发现

  * **白色路径定理**：定理22.9

* 边的分类

  * 树边
  * 后向边
  * 前向边
  * 横向边
  * 具体信息参考书p353
  * 无向图带来的模糊性
  * 定理22.10

##### 22.4 拓扑排序

* 是G中所有结点的一种线性次序

* 针对有向无环图

* TOPOLOGICAL-SORT(G): 结点次序与结点完成时间.f相反，后完成的(即.f值大的)在次序靠前处

  时间复杂度$Theta(V+E)$

* 引理22.11，22.12

##### 22.5 强连通分量

* 定义

* 图的转置$G^T=(V,E^T)$,  创建时间为$O(V+E)$

  与G的强连通分量完全相同

* STRONGLY-CONNECTED-COPONENTS(G)用两次DFS计算出G的强连通分量，$\Theta(V+E)$

* 分量图概念:是一个有向无环图

* 引理22.13，22.14，推论22.15，定理22.16

* 本质上：第二次深度优先搜索是以拓扑排序次序访问$G^{SCC}$中的结点





### 第 23 章 最小生成树

##### 概述

* 生成树、最小生成树问题
* Kruskal算法，Prim算法
* 用到的数据结构：普通二叉堆O(E lgV) ;  斐波那契堆: O(E+V lgV)

##### 23.1 最小生成树的形成

* 均是对无向图

* 贪心策略：循环不变式以及算法GENERIC_MST(G,w)

  安全边

* 切割、边横跨切割、切割尊重集合A、轻量级边

* 辨认安全边的规则：定理23.1



##### 23.2 Kruskal算法和Prim算法

* Kruskal算法：每次选择一条当前最小的边，且满足边的两端点不在一个集合里

  * 算法MST-KRUSKAL(G,w)

  * 运行时间依赖于不相交集合数据结构的实现方式

    O(ElgE)或O(ElgV)

* Prim算法：

  * 实现的要求：快速选择一条新的边
  * 最小优先队列Q



### 第 24 章 单源最短路径

##### 概述

* 最短路径问题：路径权重、最短路径权重
* 单源最短路径问题：不满足最优性原理？？？
  
* 若从源结点s可以到达权重为负的环路，则最短路径权重可能无定义
  
* 单源简单最短路径问题：满足最优性原理？？？？？
  
* 问题始终有意义
  
* 变体：单目的地最短路径问题、单结点对最短路径问题、所有结点对最短路径问题

* 最短路径的最优子结构：最短路径的子路径也是最短路径

* Dijkstra：所有边权重非负值

* Bellman-Ford：允许包含负权重的边，且若从源结点s可以到达权重为负的环路，则会报错；否则得到正确答案。

* 最短路径的表示：前驱结点、前驱子图

  * 最短路径树：包含的三个条件：书p376底部

    最短路径树可能不唯一

* 松弛操作：维持一个属性v.d,记录从源节点s到结点v的最短路径权重的上界，即最短路径估计

  * RELAX(u，v，w)
  * 这是唯一导致最短路径估计和前驱结点发生变化的操作

* 初始化：INITIALIZE-SINGLE-SOURCE(G,s)，  $\Theta(V)$

* 最短路径和松弛操作的性质

  * 三角不等式性质
  * 上界性质
  * 非路径性质
  * 收敛性质
  * 路径松弛性质
  * 前驱子图性质

##### 24.1 Bellman-Ford算法

* BELLMAN-FORD（G,w,s）
* 时间：$O(VE)$,若能按最佳顺序(DAG的拓扑排序次序)，则只需1趟，O(V)
* 算法的正确性：引理24.2，推论24.3，定理24.4

##### 24.2 有向无环图中的单源最短路径问题

* DAG-SHORTEST-PATHS(G,w,s)
* 定理24.5：算法正确性证明
* 算法应用：PERT图的关键路径分析

##### 24.3 Dijkstra算法

* 解决带权重的**有向图**上单源最短路径问题，要求所有边权重都为非负值。

* DIJKSTRA(G,w,s)

* 定理24.6：算法正确性

* 推论24.7

* 算法性能分析：依赖于最小优先队列的实现

  * 数组实现：$O(V^2)$

  * 稀疏图时二叉堆实现：$O((V+E)lgV)$

    若所有结点都可从源节点到达(此时E>=V),则为$O(ElgV)$

  * 斐波那契堆：摊还代价$O(VlgV+E)$

* Dijkstra算法与Prim、广度优先搜索的相似处

* ![image-20210110180901571](D:\Typora\ASC\image-20210110180901571.png)

##### 24.4 差分约束和最短路径



### 第 25 章 所有结点对的最短路径问题

##### 概述

* V次Dijkstra算法
  * 线性数组 ：$O(V^3)$
  * 二叉堆实现：$O(VElgV)$
  * 斐波那契堆：摊还代价$O(V^2lgV+VE)$
* 含有权重为负值的边：Bellman-Ford作N次
  * $O(V^2E)$
  * 若是稠密图:$O(V^4)$

* 邻接矩阵与邻接链表表示

* 算法输入：矩阵W；   输出：矩阵D

* 前驱结点矩阵、前驱子图、最短路径树

  PRINT-ALL-PAIRS-SHORTEST-PATH($\pi$,i,j):打印i到j的最短路径

##### 25.1 最短路径和矩阵乘法

* 最短路径的结构
* 所有结点对最短路径问题的递归解
* 自底向上计算最短路径权重
* 改进算法的运行时间：重复平方技术
* ？？？最短路径问题怎么转成矩阵乘法的？

##### 25.2 Floyd-Warshall算法

* 最短路径的结构：从结点编号入手切分子问题

* 所有结点对最短路径问题的一个递归解：式25.5

* 自底向上计算最短路径权重

  FLOYD-WARSHALL(W)

  时间复杂度：$\Theta(n^3)$

  简化存储：书题目25.2-4  ,D和$\Pi$矩阵都可以简化

* 构建一条最短路径：$\pi$矩阵的计算：式25.7

* 有向图的传递闭包

* 关于邻接矩阵自乘的性质：https://blog.csdn.net/niiick/article/details/82805779

  对应书p402下一页的笔记

##### 25.3 用于稀疏图的Johnson算法

* 时间复杂度$ O(V^2lgV+VE)$(fibonacci)或$O(VElgV)$(二叉最小堆)
* 思路：重新赋予权重
  * 若边权重全为非负，则全部Dijkstra算法（且斐波那契堆最小优先队列）
  * 若有权重为负值的边，但无权重为负值的环路->  算出一组新的非负权重值
    * 重新赋予权重的要求：两点，最后此步时间复杂度为O(VE)
    * 定理25.1：重新赋予权重并不改变最短路径
    * 

### 第 30 章 多项式与快速傅里叶变换

##### 概述

* 多项式次数、次数界
* 多项式乘法、加法

##### 30.1 多项式的表示

* 系数表达：正常A*B需$\Theta(n^2)$
  * 多项式求值：霍纳法则
  * 向量a,b的卷积
* 点值表达: 
  * 系数表达->点值表达：简答
  * 点值表达 -> 系数表达：插值
    * 拉格朗日插值多项式
    * 插值多项式的唯一性：定理30.1
  * 点值表达下
    * 多项式加法：$\Theta(n)$
    * 多项式乘法: 需要A，B各出2n个点值对，相乘也只需要$\Theta(n)$
  * 系数形式表示的多项式的快速乘法：图30-1
    * 选择2n次单位负数根来作为求值点， 系数表示(输入)->DFT->点值表示->求乘法->点值表示(输出)->逆DFT->系数表示(输出)
    * 只需$\Theta(nlgn)$
    * 注意添加系数为0的高阶系数来调整次数界和n的值
    * 求值步骤：
      1. 加倍次数界
      2. 求值
      3. 逐点相乘
      4. 插值



##### 30.2 DFT与FFT

* 数学基础
  * 单位复数根$\omega_n$
  * 主n次单位根
  * 消去引理
  * 推论30.4
  * 折半引理
  * 求和引理
* 离散傅里叶变换DFT定义
* 快速傅里叶变换FFT：考虑分治策略，对A(x)奇偶下标的项分离，转换为求次数界为n/2的两个多项式在n/2个n/2次单位复数根处的值。
  * 算法RECURSIVE-FFT(a)
  * 时间复杂度$\Theta(nlgn)$
  * 旋转因子$\omega^k_n$

##### 30.3 高效FFT实现





### 第 32 章 字符串匹配

##### 概述

* 问题的形式化定义

* 有效偏移

* 总体流程：预处理+匹配

  图32-2：时间复杂度

* 符号和术语
  * 连结
  * 前后缀、传递关系、后缀重叠引理

##### 32.1 朴素字符串匹配算法

* NAIVE-STRING-MATCHING(T,P)
* 时间复杂度$O((n-m+1)m)$,无预处理

##### 32.2 Rabin-Karp算法

* 预处理时间$\Theta(m)$ , 运行时间$\Theta((n-m+1)m)$，运行时间有期望O(n+m)

  模式 长为m， 文本长为n

* 思路：为每个长为m的串 赋一个值， 当$f(P)=f(T_m)$是算是1次成功匹配

  快速计算：式32.1

* 改进（防止数字过大）：取模运算，式32.2

  * 书p581 图c算例
  * 伪命中点
  * 书p582算法：基数d、素数p的选取

##### 32.3 利用有限自动机进行字符串匹配

* 有限自动机的5元组定义：状态集、初始状态、接受状态、输入字母表、转移函数$\delta$
* 终态函数$\phi$ ：不用管

* 字符串匹配自动机

  * $\sigma$ ：后缀函数 ，定义及计算：书p584

  * 转换函数图见p585， 状态数为m+1 (P的串长为m)，0为初态，m为末态，状态的数字代表已经匹配了$P_k$

    例子参见ipad书585

* 预处理时间$O(m| \sum^{}_{}|)$，  运行时间（匹配时间）$\Theta(n)$

* 引理：32.2， 32.3

* 计算转移函数：算法见p587， 复杂度 $O(m^3| \sum^{}_{}|)$

  可改进到预处理时间为$O(m| \sum^{}_{}|)$



##### 32.4 KMP算法

* 匹配时间$\Theta(n)$,  预处理时间$\Theta(m)$

* 辅助函数$\pi$

* 模式的前缀函数:用于计算P要左移多少才能和当前已匹配到的$P_k$最大程度上再次匹配

  书p588 图32-10例子

* 两个算法见书p590，注意两个算法思路的一致性